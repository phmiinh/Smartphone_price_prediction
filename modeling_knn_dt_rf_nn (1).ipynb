{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Modeling: KNN, Decision Tree, Random Forest, Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "load_prepare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 908 rows and 16 columns\n",
      "Using 15 features for modeling\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "FILE_PATH = \"mobiles_dataset_2025_processed.csv\"\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "print(f\"Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "\n",
    "# Target and feature selection\n",
    "TARGET = 'Launched Price (USA)'\n",
    "\n",
    "# If your file contains columns with encoded companies/processors like in prior notebook, include them.\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if TARGET not in numeric_cols:\n",
    "    raise KeyError(f\"Target column '{TARGET}' not found as numeric column in dataframe\")\n",
    "feature_cols = [c for c in numeric_cols if c != TARGET]\n",
    "\n",
    "# Minimal cleaning: drop rows with missing target, impute numeric features later in pipeline\n",
    "df = df.dropna(subset=[TARGET]).reset_index(drop=True)\n",
    "X = df[feature_cols]\n",
    "y = df[TARGET]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features for modeling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "split_scale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (726, 15) (182, 15)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "RANDOM_STATE = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Preprocessing pipeline: impute then scale (fit on train)\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_prep = numeric_pipeline.fit_transform(X_train)\n",
    "X_test_prep = numeric_pipeline.transform(X_test)\n",
    "\n",
    "print('Shapes:', X_train_prep.shape, X_test_prep.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "eval_helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(true, pred):\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "    r2 = r2_score(true, pred)\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "def print_eval(name, true, pred):\n",
    "    res = evaluate_regression(true, pred)\n",
    "    print(f\"{name}: MAE={res['MAE']:.3f}, RMSE={res['RMSE']:.3f}, R2={res['R2']:.3f}\")\n",
    "    return res\n",
    "\n",
    "def _is_fitted(est):\n",
    "    try:\n",
    "        check_is_fitted(est)\n",
    "        return True\n",
    "    except (NotFittedError, AttributeError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "models_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_knn already fitted\n",
      "best_dt already fitted\n",
      "rf already fitted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ensure estimator objects exist\n",
    "if 'best_knn' in globals() and isinstance(best_knn, int):\n",
    "    best_knn = KNeighborsRegressor(n_neighbors=best_knn)\n",
    "elif 'best_knn' not in globals():\n",
    "    best_knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "if 'best_dt' not in globals():\n",
    "    best_dt = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "if 'rf' not in globals():\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "# Fit if needed (use train data already prepared)\n",
    "for name, est in [('best_knn', best_knn), ('best_dt', best_dt), ('rf', rf)]:\n",
    "    if not _is_fitted(est):\n",
    "        print(f\"{name} not fitted -> fitting now\")\n",
    "        est.fit(X_train_prep, y_train)\n",
    "    else:\n",
    "        print(f\"{name} already fitted\")\n",
    "# Build pipelines that include the fitted numeric_pipeline (so preprocessing is saved together)\n",
    "from sklearn.pipeline import Pipeline as SKPipeline\n",
    "knn_pipe = SKPipeline([('preprocessor', numeric_pipeline), ('model', best_knn)])\n",
    "dt_pipe  = SKPipeline([('preprocessor', numeric_pipeline), ('model', best_dt)])\n",
    "rf_pipe  = SKPipeline([('preprocessor', numeric_pipeline), ('model', rf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: MAE=1.101, RMSE=1.640, R2=0.838\n",
      "DecisionTree: MAE=1.035, RMSE=1.574, R2=0.851\n",
      "RandomForest: MAE=0.957, RMSE=1.356, R2=0.889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>1.100837</td>\n",
       "      <td>1.640172</td>\n",
       "      <td>0.838063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>1.035423</td>\n",
       "      <td>1.574037</td>\n",
       "      <td>0.850859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.956592</td>\n",
       "      <td>1.356167</td>\n",
       "      <td>0.889288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MAE      RMSE        R2\n",
       "KNN           1.100837  1.640172  0.838063\n",
       "DecisionTree  1.035423  1.574037  0.850859\n",
       "RandomForest  0.956592  1.356167  0.889288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Evaluate on test set (use X_test_prep which is preprocessed)\n",
    "results = {}\n",
    "knn_pred = best_knn.predict(X_test_prep)\n",
    "results['KNN'] = print_eval('KNN', y_test, knn_pred)\n",
    "\n",
    "dt_pred = best_dt.predict(X_test_prep)\n",
    "results['DecisionTree'] = print_eval('DecisionTree', y_test, dt_pred)\n",
    "\n",
    "rf_pred = rf.predict(X_test_prep)\n",
    "results['RandomForest'] = print_eval('RandomForest', y_test, rf_pred)\n",
    "\n",
    "summary = pd.DataFrame(results).T\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "save_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: knn_model.pkl, decision_tree_model.pkl, random_forest_model.pkl,\n",
      "       knn_model.joblib, decision_tree_model.joblib, random_forest_model.joblib,\n",
      "       neural_net_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save sklearn models with pkl\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Tạo pipeline chứa cả preprocessing đã fit + model (tiện cho inference)\n",
    "knn_pipe = Pipeline([('preprocessor', numeric_pipeline), ('model', best_knn)])\n",
    "dt_pipe  = Pipeline([('preprocessor', numeric_pipeline), ('model', best_dt)])\n",
    "rf_pipe  = Pipeline([('preprocessor', numeric_pipeline), ('model', rf)])\n",
    "\n",
    "# Lưu bằng pickle (.pkl) \n",
    "with open('knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_pipe, f)\n",
    "with open('decision_tree_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_pipe, f)\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_pipe, f)\n",
    "\n",
    "print('Saved: knn_model.pkl, decision_tree_model.pkl, random_forest_model.pkl,')\n",
    "print('       knn_model.joblib, decision_tree_model.joblib, random_forest_model.joblib,')\n",
    "print('       neural_net_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c279ffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from knn_model.pkl\n",
      "Giá dự đoán (raw): 11.656666666666666\n",
      "≈ Giá (USD): 1165.6666666666665\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "import re, os, pickle, joblib\n",
    "\n",
    "# 1) Tạo DataFrame input\n",
    "new_phone = pd.DataFrame([{\n",
    "    'Company Name': 'Oppo',\n",
    "    'RAM': '12GB',\n",
    "    'ROM': '256GB',\n",
    "    'Front Camera': '50MP',\n",
    "    'Back Camera': '50MP',\n",
    "    'Battery Capacity': '5000mAh',\n",
    "    'Screen Size': '6.9 inches',\n",
    "    'Processor': 'Snapdragon 8 gen 2'\n",
    "}])\n",
    "\n",
    "# 2) Tiền xử lý nhỏ giống notebook\n",
    "def clean_numeric(series, remove_str=\"\", round_to_int=False):\n",
    "    s = (series.astype(str)\n",
    "         .str.replace(remove_str, \"\", regex=False)\n",
    "         .str.replace(\"Not available\", \"\", regex=False)\n",
    "         .str.replace(\",\", \"\", regex=False)\n",
    "         .str.extract(r\"(\\d+\\.?\\d*)\")[0])\n",
    "    out = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if round_to_int:\n",
    "        out = out.round().astype(\"Int64\")\n",
    "    return out\n",
    "\n",
    "def extract_rom(model_name):\n",
    "    mn = str(model_name).upper()\n",
    "    m_tb = re.search(r'(\\d+)TB', mn)\n",
    "    if m_tb:\n",
    "        return float(m_tb.group(1)) / 64 * 1024\n",
    "    m_gb = re.search(r'(\\d+)GB', mn)\n",
    "    if m_gb:\n",
    "        return float(m_gb.group(1)) / 64\n",
    "    return np.nan\n",
    "\n",
    "new_phone[\"RAM\"] = clean_numeric(new_phone[\"RAM\"], remove_str=\"GB\", round_to_int=True)\n",
    "new_phone['ROM'] = clean_numeric(new_phone[\"ROM\"], remove_str=\"GB\", round_to_int=True)\n",
    "new_phone[\"Front Camera\"] = clean_numeric(new_phone[\"Front Camera\"], remove_str=\"MP\") / 10\n",
    "new_phone[\"Back Camera\"]  = clean_numeric(new_phone[\"Back Camera\"], remove_str=\"MP\") / 10\n",
    "new_phone[\"Battery Capacity\"] = clean_numeric(new_phone[\"Battery Capacity\"], remove_str=\"mAh\", round_to_int=True) / 1000\n",
    "new_phone[\"Screen Size\"] = clean_numeric(new_phone[\"Screen Size\"], remove_str=\"inches\")\n",
    "\n",
    "# Company dummy (safest: keep the value and create dummies later based on model's expected cols)\n",
    "company_value = new_phone.loc[0, \"Company Name\"]\n",
    "\n",
    "# 3) Load processor vectorizer + pca if available\n",
    "proc_vec = None\n",
    "proc_cols = []\n",
    "if os.path.exists('processor_vectorizer.pkl') and os.path.exists('processor_pca.pkl'):\n",
    "    with open('processor_vectorizer.pkl','rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "    with open('processor_pca.pkl','rb') as f:\n",
    "        pca = pickle.load(f)\n",
    "    try:\n",
    "        tf = vectorizer.transform(new_phone[\"Processor\"])\n",
    "        pv = pca.transform(tf.toarray())\n",
    "        proc_df = pd.DataFrame(pv, index=new_phone.index,\n",
    "                               columns=[f\"Processor_vec{i+1}\" for i in range(pv.shape[1])])\n",
    "        new_phone = pd.concat([new_phone.reset_index(drop=True), proc_df.reset_index(drop=True)], axis=1)\n",
    "        proc_cols = proc_df.columns.tolist()\n",
    "    except Exception as e:\n",
    "        print(\"Processor transform failed:\", e)\n",
    "\n",
    "# 4) Load model (try best_model first)\n",
    "model = None\n",
    "for fname in ['knn_model.pkl','decision_tree_model.pkl','random_forest_model.pkl']:\n",
    "    if os.path.exists(fname):\n",
    "        try:\n",
    "            model = joblib.load(fname) if fname.endswith('.joblib') else pickle.load(open(fname,'rb'))\n",
    "            print(\"Loaded model from\", fname)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Failed loading\", fname, \":\", e)\n",
    "if model is None:\n",
    "    raise FileNotFoundError(\"Không tìm thấy model .pkl/.joblib\")\n",
    "\n",
    "# 5) Determine required feature names (prefer preprocessor/imputer feature_names_in_ if pipeline)\n",
    "required_cols = None\n",
    "if hasattr(model, 'named_steps') and 'preprocessor' in model.named_steps:\n",
    "    pre = model.named_steps['preprocessor']\n",
    "    # pre may be a Pipeline where imputer has feature_names_in_\n",
    "    if hasattr(pre, 'feature_names_in_'):\n",
    "        required_cols = list(pre.feature_names_in_)\n",
    "    else:\n",
    "        # try to get imputer inside pre\n",
    "        try:\n",
    "            imputer = pre.named_steps.get('imputer', None)\n",
    "            if imputer is not None and hasattr(imputer, 'feature_names_in_'):\n",
    "                required_cols = list(imputer.feature_names_in_)\n",
    "        except Exception:\n",
    "            required_cols = None\n",
    "\n",
    "if required_cols is None:\n",
    "    if hasattr(model, 'feature_names_in_'):\n",
    "        required_cols = list(model.feature_names_in_)\n",
    "    else:\n",
    "        # fallback: use columns in training X if you stored them somewhere (not available) -> use new_phone cols\n",
    "        required_cols = list(new_phone.columns)\n",
    "\n",
    "# 6) Build aligned single-row DataFrame X_in with required_cols\n",
    "X_in = pd.DataFrame(index=[0])\n",
    "for col in required_cols:\n",
    "    if col in new_phone.columns:\n",
    "        X_in[col] = new_phone.loc[0, col]\n",
    "    elif col.startswith(\"Company_\"):\n",
    "        # set company dummy: e.g. Company_Oppo -> 1 if company_value == \"Oppo\"\n",
    "        comp_name = col.split(\"Company_\")[-1]\n",
    "        X_in[col] = 1 if comp_name == company_value else 0\n",
    "    elif re.match(r'Processor_vec\\d+', col):\n",
    "        X_in[col] = new_phone.loc[0, col] if col in new_phone.columns else 0.0\n",
    "    else:\n",
    "        X_in[col] = 0.0\n",
    "\n",
    "# Ensure column order matches required_cols\n",
    "X_in = X_in.reindex(columns=required_cols, fill_value=0)\n",
    "\n",
    "# 7) Predict (pipeline or estimator)\n",
    "try:\n",
    "    pred = model.predict(X_in)\n",
    "except Exception as e:\n",
    "    # if model is pipeline expecting DataFrame with original columns, try passing X_in.values\n",
    "    pred = model.predict(X_in.values)\n",
    "print(\"Giá dự đoán (raw):\", pred[0])\n",
    "try:\n",
    "    print(\"≈ Giá (USD):\", float(pred[0]) * 100)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Inspect feature importance from RandomForest via rf.feature_importances_ if desired.\n",
    "- Further tuning (e.g., RandomizedSearchCV), target transformation (log), or categorical encoding may improve performance.\n",
    "- Adjust dataset path and feature selection according to your processed CSV structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
